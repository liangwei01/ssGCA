{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3c3349-48f4-4a07-8a66-a9270c02f7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import exp\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "from statistics import mean, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513ce541-fc47-4d7e-a736-2c408e74f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_law(x1, a, b):\n",
    "    return a*np.power(x1, b)\n",
    "\n",
    "def get_r2(g):\n",
    "    \"\"\"\n",
    "    generate the R2 rate for network scale free topology \n",
    "    \"\"\"\n",
    "    #number of edges: g.ecount()  number of vertices: g.vcount()\n",
    "    print(g.ecount())\n",
    "    sam_density = g.ecount()/(g.vcount()*(g.vcount()-1)/2)\n",
    "    degree_sequence = sorted([d for d in g.degree()], reverse=True) \n",
    "    degree_out = {}\n",
    "    for i in degree_sequence:\n",
    "        if i in degree_out.keys():\n",
    "            degree_out[i] += 1\n",
    "        else:\n",
    "            degree_out[i] = 1\n",
    "    x = [int(i) for i in degree_out.keys()]\n",
    "    y = [int(degree_out[i]) for i in x]\n",
    "    popt, pcov = curve_fit(power_law, x, y)\n",
    "    # get r2 via method 2\n",
    "    r_squared_2 = r2_score(y, power_law(x, *popt), multioutput='variance_weighted')\n",
    "    return [sam_density, r_squared_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eca5393-95d9-4b1a-8627-376fa73ea13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://uppsala.instructure.com/courses/52162/pages/\n",
    "##lab-network-construction-and-analysis-of-a-transcriptomic-and-metabolomic-dataset?module_item_id=310013\n",
    "#function to get graph properties, takes a few minutes to run\n",
    "def graph_prop(nn):\n",
    "    \"\"\"\n",
    "    generate network features\n",
    "    \"\"\"\n",
    "    a = time.time()\n",
    "    ncount=nn.vcount()\n",
    "    print(time.time()-a,\"1 step\")\n",
    "    a = time.time()\n",
    "    ecount=nn.ecount()\n",
    "    print(time.time()-a,\"2 step\")\n",
    "    a = time.time()\n",
    "    kk = nn.degree()\n",
    "    print(time.time()-a,\"3 step\")\n",
    "    a = time.time()\n",
    "    kk = [mean(kk),median(kk),max(kk)]\n",
    "    print(time.time()-a,\"4 step\")\n",
    "    a = time.time()\n",
    "    \"\"\"\n",
    "    diameter=nn.diameter()\n",
    "    print(time.time()-a,\"5 step\")\n",
    "    a = time.time()\n",
    "    av_path=nn.average_path_length()\n",
    "    print(time.time()-a,\"6 step\")\n",
    "    a = time.time()\n",
    "    \"\"\"\n",
    "    dens=nn.density()\n",
    "    print(time.time()-a,\"7 step\")\n",
    "    \"\"\"\n",
    "    a = time.time()\n",
    "    clustering=nn.transitivity_undirected() #this is the global clustering coefficient\n",
    "    print(time.time()-a,\"8 step\")\n",
    "    \"\"\"\n",
    "    a = time.time()\n",
    "    conn=nn.is_connected()\n",
    "    print(time.time()-a,\"9 step\")\n",
    "    \"\"\"\n",
    "    a = time.time()\n",
    "    min_cut=nn.mincut_value()\n",
    "    print(time.time()-a,\"10 step\")\n",
    "    \"\"\"\n",
    "    out = [ncount, ecount] + kk + [dens, conn]# clustering, min_cut\n",
    "    #out=pd.DataFrame([ncount, ecount,kmean, kmedian,kmax, diameter, av_path, dens, clustering, conn, min_cut],\n",
    "     #            index=['node_count','edge_count','kmean', 'kmedian','kmax','diameter','av_path_length','density','clustering_coef','connected?','minimum_cut']).T\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73de06e9-1716-4484-a12e-40d811fd9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_nn_feature(sample_file):\n",
    "    print(sample_file)\n",
    "    file = f\"./{sampleGroup}/sample_specific_{sample_file}.txt\"\n",
    "    df = pd.read_csv(file,sep=\"\\t\",header=None)\n",
    "    df.columns = [\"node1\", \"node2\",\"weight\" ]\n",
    "    df[\"weight\"] = abs(df[\"weight\"])\n",
    "    sampleGCN = ig.Graph.TupleList(df.itertuples(index=False),edge_attrs=\"weight\")\n",
    "    all_result= get_r2(sampleGCN) + graph_prop(sampleGCN)\n",
    "    return sample_file+\"\\t\".join([str(temp) for temp in all_result])+\"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bae478e7-eb7e-414e-b483-69e615dd0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleGroup = \"primaryNivo\"\n",
    "all_sample = []\n",
    "with open(f\"{sampleGroup}.weight.txt\") as f_w:\n",
    "     for i in f_w:\n",
    "         i= i.strip().split()\n",
    "         all_sample.append(i[0])\n",
    "\n",
    "network_stats = open(f\"{sampleGroup}_network_stats.txt\",\"w+\")\n",
    "\n",
    "headerline = [\"sample_name\",\"density\", \"r2\",\\\n",
    "            'node_count','edge_count','kmean', \\\n",
    "              'kmedian','kmax',\\\n",
    "              'density','connected?']\n",
    "\n",
    "network_stats.write(\"\\t\".join(headerline)+\"\\n\")\n",
    "network_stats.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a4b8bd-d2b4-4399-8675-515beee7dafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EA595500\n",
      "2622569\n",
      "2.6226043701171875e-06 1 step\n",
      "1.1920928955078125e-06 2 step\n",
      "0.00020933151245117188 3 step\n",
      "0.004143953323364258 4 step\n",
      "0.0005602836608886719 7 step\n",
      "0.022661209106445312 9 step\n"
     ]
    }
   ],
   "source": [
    "for i in all_sample:\n",
    "    get_all_nn_feature(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae153b-1a5a-4f10-9a9c-a4b559793cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiproceesing must in    if __name__ == \"__main__\":\n",
    "result = []\n",
    "for  i in all_sample[:3]:\n",
    "    result.append(get_all_nn_feature(i))\n",
    "network_stats = open(f\"{sampleGroup}_network_stats.txt\",\"w\")\n",
    "network_stats.write(\"\".join(result))\n",
    "network_stats.close()\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "if __name__ == \"__main__\":\n",
    "    aaa = time.time()\n",
    "    \"\"\"\n",
    "    #for loop 12 seconds for 3 samples\n",
    "        result = []\n",
    "    for  i in all_sample[:3]:\n",
    "        result.append(get_all_nn_feature(i))\n",
    "    \"\"\"\n",
    "\n",
    "    p = Pool(cpu_count()-1)\n",
    "    result = []\n",
    "    ###used method 4 seconds for 3 samples\n",
    "    result = p.map(get_all_nn_feature, all_sample[:3])\n",
    "    p.close()\n",
    "    p.join()\n",
    "    network_stats = open(f\"{sampleGroup}_network_stats.txt\",\"w\")\n",
    "    print([i for i in result])\n",
    "    network_stats.write(\"\".join(result))\n",
    "    network_stats.close()\n",
    "    print(\"used time: \", time.time()-aaa)\n",
    "    print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01e6a4-c88b-4a2e-b16f-e98ff327ce59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
